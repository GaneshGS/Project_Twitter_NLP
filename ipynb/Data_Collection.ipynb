{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): twitter in /opt/conda/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): tweepy in /opt/conda/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests-oauthlib>=0.4.1 in /opt/conda/lib/python3.5/site-packages (from tweepy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests>=2.4.3 in /opt/conda/lib/python3.5/site-packages (from tweepy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.7.3 in /opt/conda/lib/python3.5/site-packages (from tweepy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): oauthlib>=0.6.2 in /opt/conda/lib/python3.5/site-packages (from requests-oauthlib>=0.4.1->tweepy)\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "from lib.twitter_keys import keys\n",
    "!pip install twitter tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'twitter_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f5b1b2ce8e10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#sys.path.insert(0,parentdir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtwitter_keys\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtwitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOAuth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTwitterHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTwitterStream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'twitter_keys'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os,sys,inspect\n",
    "from time import sleep\n",
    "#currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "#parentdir = os.path.dirname(currentdir)\n",
    "#sys.path.insert(0,parentdir)\n",
    "\n",
    "from twitter_keys import keys\n",
    "import json\n",
    "from twitter import Twitter, OAuth, TwitterHTTPError, TwitterStream\n",
    "\n",
    "\n",
    "CONSUMER_KEY = keys['CONSUMER_KEY']\n",
    "CONSUMER_SECRET = keys['CONSUMER_SECRET']\n",
    "ACCESS_TOKEN = keys['ACCESS_TOKEN']\n",
    "ACCESS_SECRET = keys['ACCESS_SECRET']\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### geo bounding for tweet location----------------------------------------------------####\n",
    "\n",
    "los_angeles = \"-118.670883,33.733477,-117.695847,34.290126\"\n",
    "Santa_Monica = \"-118.514757,33.980857,-118.417253,34.065264\"\n",
    "Dallas = \"-96.904907,32.761906,-96.684917,33.080035\"\n",
    "Midland_Odessa = \"-103.1575,31.4849,-101.5178,32.3591\"\n",
    "Sacramento_east = \"-121.8658,38.445,-120.2618,39.3598\"\n",
    "SFO = \"-122.5319,37.5751,-122.3438,37.824\"\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### connect to postgres----------------------------------------------------------------####\n",
    "\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "\n",
    "\n",
    "### ------------------------------------------------------------------------------------####\n",
    "### cleaning text ----------------------------------------------------------------------####\n",
    "\n",
    "def cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"'\",\"''\", text)\n",
    "    text = re.sub(\"{\",\"\\{\",text)\n",
    "    text = re.sub(\"}\",\"\\}\",text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "\n",
    "    #text = re.sub(\":\",\"\\:\",text)\n",
    "    return text\n",
    "\n",
    "### -------------------------------------------------------------------------------------####\n",
    "### cleaning tweet ----------------------------------------------------------------------####\n",
    "\n",
    "#from spacy.en import STOP_WORDS\n",
    "#from spacy.en import English\n",
    "#import nltk\n",
    "#nlp = English()\n",
    "def tweet_cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"'\",\"''\", text)\n",
    "    text = re.sub(\"{\",\"\\{\",text)\n",
    "    text = re.sub(\"}\",\"\\}\",text)\n",
    "    text = re.sub(r'http\\S+', '',text)\n",
    "    text = re.sub(r'@\\S+', '',text)\n",
    "    \n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    text = re.sub('\\n',' ',text) \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = re.sub(emoji_pattern, '', text)    \n",
    "#    text = ' '.join([i.lemma_ for i in nlp(text) \n",
    "#                   if i.orth_ not in STOP_WORDS])\n",
    "    \n",
    "    return text\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### Collecting tweets------------------------------------------------------------------####\n",
    "\n",
    "\n",
    "\n",
    "oauth = OAuth(ACCESS_TOKEN, ACCESS_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_stream = TwitterStream(auth=oauth)\n",
    "#iterator = twitter_stream.statuses.filter(locations=Santa_Monica+','+\\\n",
    "#                                          Midland_Odessa+','+Dallas+','+\\\n",
    "#                                          Sacramento_east+','+SFO)\n",
    "iterator = twitter_stream.statuses.filter(locations=los_angeles)\n",
    "tweet_count = 300000\n",
    "\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "for tweet in iterator:\n",
    "    tweet_count -= 1  \n",
    "   \n",
    "    try:\n",
    "        id_str = str(tweet['id_str'])\n",
    "    except:    \n",
    "        id_str = None\n",
    "    try:\n",
    "        screen_name = tweet['user']['screen_name']\n",
    "    except:\n",
    "        screen_name = None\n",
    "\n",
    "    tweet_content = cleaner(tweet['text'])\n",
    "    cleaned_tweet = tweet_cleaner(tweet['text'])\n",
    "    screen_name = tweet['user']['screen_name']\n",
    "    retweeted = tweet['retweeted']\n",
    "    retweet_count = tweet['retweet_count']\n",
    "    created_at = tweet['created_at']\n",
    "    \n",
    "    get_hashtags = lambda tweet: \" \".join([i for i in tweet.split() if ('#' in i)])\n",
    "    hashtags1 = get_hashtags(tweet_content)\n",
    "    hashtags1 = re.sub('\\W',' ',hashtags1)\n",
    "    hashtags1 = re.sub('\\s+',' ',hashtags1)\n",
    "    try: \n",
    "        if len(hashtags1) > 1:\n",
    "            hashtags = hashtags1\n",
    "        else:\n",
    "            hashtags = None\n",
    "    except:\n",
    "        hashtags = None\n",
    "    try:\n",
    "        location =  cleaner(tweet['place']['full_name'])\n",
    "    except:\n",
    "        location = None\n",
    "    try:\n",
    "        country = tweet['place']['country']\n",
    "    except:\n",
    "        country = None\n",
    "    try:\n",
    "        place_type = tweet['place']['place_type']\n",
    "    except:\n",
    "        place_type = None\n",
    "    try:\n",
    "        latitude = tweet[\"geo\"][\"coordinates\"][0]\n",
    "        longitude = tweet[\"geo\"][\"coordinates\"][1]\n",
    "    except:\n",
    "        latitude = 0.0 \n",
    "        longitude = 0.0  \n",
    "    usr= tweet['user']\n",
    "    lang = tweet['lang']\n",
    "    try:\n",
    "        time_zone = cleaner(tweet['user']['time_zone'])\n",
    "    except:\n",
    "        time_zone = None    \n",
    "    sql_insert = '''insert into tweets \n",
    "                        (\n",
    "                            id,\n",
    "                            screen_name,\n",
    "                            tweet_content,\n",
    "                            cleaned_tweet,\n",
    "                            hashtags,\n",
    "                            created_at,\n",
    "                            retweeted,\n",
    "                            retweet_count,\n",
    "                            location,\n",
    "                            country,\n",
    "                            place_type,\n",
    "                            latitude,\n",
    "                            longitude, \n",
    "                            time_zone,\n",
    "                            lang\n",
    "                        )\n",
    "                    values\n",
    "                        ('{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}');\n",
    "                 '''.format(id_str,\n",
    "                            screen_name,\n",
    "                            tweet_content,\n",
    "                            cleaned_tweet,\n",
    "                            hashtags,\n",
    "                            created_at,\n",
    "                            retweeted,\n",
    "                            retweet_count,\n",
    "                            location,\n",
    "                            country,\n",
    "                            place_type,\n",
    "                            latitude,\n",
    "                            longitude,\n",
    "                            time_zone,\n",
    "                            lang\n",
    "                           )\n",
    "    print(str(tweet_count)+' '+ screen_name+ ':  '+ tweet_content)\n",
    "    #print(latitude,longitude)\n",
    "    cur.execute(sql_insert)\n",
    "    \n",
    "    conn.commit()    \n",
    "    if tweet_count <= 0:\n",
    "        break\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "select count(*) from tweets;\n",
    "\n",
    "##### create able\n",
    "select * into tweets_bkup_0607 from tweets;\n",
    "\n",
    "CREATE TABLE tweets (\n",
    "    id TEXT, \n",
    "    tweet_content TEXT, \n",
    "    entities TEXT,\n",
    "    retweeted TEXT,\n",
    "    created_at TEXT,\n",
    "    regin TEXT,\n",
    "    country TEXT,\n",
    "    place_type TEXT,\n",
    "    geo_enabled boolean,\n",
    "    geo text,\n",
    "    time_zone TEXT,\n",
    "    lang TEXT,\n",
    "    usr text\n",
    "    );\n",
    "    \n",
    "##### drop table\n",
    "drop table tweets_bkup_0606;\n",
    "\n",
    "##### set ID/ Index\n",
    "alter table tweets alter column id set not null;\n",
    "alter table tweets add unique (id);\n",
    "\n",
    "create index on tweets (id);\n",
    "create index on tweets (tweet_content);\n",
    "\n",
    "##### clean table\n",
    "select count (*) from tweets where hashtags = 'None';\n",
    "select count (*) from tweets where hashtags is null;\n",
    "update tweets set hashtags = NULL where hashtags = 'None';\n",
    "\n",
    "select count(*) from tweets where lang != 'en';\n",
    "delete from tweets where lang != 'en';\n",
    "\n",
    "##### Docker - psql\n",
    "docker exec -it mypostgres psql postgres postgres\n",
    "\n",
    "##### In psql\n",
    "\\d tweets\n",
    "\\dt\n",
    "\\q\n",
    "\n",
    "##### get cloumns\n",
    "SELECT * FROM Northwind.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'tweets';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='54.191.217.176'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "cur = conn.cursor(cursor_factory=pgex.RealDictCursor)\n",
    "#cur.execute(sql_create)\n",
    "#cur.execute(sql_drop)\n",
    "#cur.execute(sql_insert)\n",
    "#conn.commit()\n",
    "cur.execute(sql_select)\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import psycopg2\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "oauth = OAuth(ACCESS_TOKEN, ACCESS_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_stream = TwitterStream(auth=oauth)\n",
    "iterator = twitter_stream.statuses.filter(locations=los_angeles_bb)\n",
    "tweet_count = 30\n",
    "\n",
    "\n",
    "\n",
    "# Twitter initialization\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "l = StreamListener()\n",
    "# Postgresql initialization\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# The table schema: CREATE TABLE tweets (id SERIAL PRIMARY KEY, tweet_id BIGINT NOT NULL, text VARCHAR NOT NULL, screen_name VARCHAR NOT NULL, author_id INTEGER, created_at VARCHAR NOT NULL, inserted_at TIMESTAMP NOT NULL)\n",
    "\n",
    "try:\n",
    "     \n",
    "    stream = Stream(auth, l)\n",
    "    count = tweet_count\n",
    "    iterator = stream.filter(locations=[-118.512139,34.003151,-118.433948,34.048961])\n",
    "    print(iterator)\n",
    "    for s in iterator:\n",
    "        # To remove duplicate entries\n",
    "        # See http://initd.org/psycopg/docs/faq.html for \"not all arguments converted during string formatting\"\n",
    "        cursor.execute(\"SELECT id FROM tweets WHERE text = %s;\", [s.text])\n",
    "        if cursor.rowcount == 0:\n",
    "            cursor.execute(\"INSERT INTO tweets (id, tweet_content, created_at) \\\n",
    "                           VALUES (%s, %s, %s, %s, %s, current_timestamp);\"\\\n",
    "                           , (s.id, s.text, s.created_at))\n",
    "            conn.commit()\n",
    "except tweepy.error.TweepError:\n",
    "    print (\"Whoops, could not fetch news!\")\n",
    "except UnicodeEncodeError:\n",
    "    pass\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
