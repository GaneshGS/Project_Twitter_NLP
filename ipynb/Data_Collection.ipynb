{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): twitter in /opt/conda/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): tweepy in /opt/conda/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests>=2.4.3 in /opt/conda/lib/python3.5/site-packages (from tweepy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests-oauthlib>=0.4.1 in /opt/conda/lib/python3.5/site-packages (from tweepy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.7.3 in /opt/conda/lib/python3.5/site-packages (from tweepy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): oauthlib>=0.6.2 in /opt/conda/lib/python3.5/site-packages (from requests-oauthlib>=0.4.1->tweepy)\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "#from lib.twitter_keys import keys\n",
    "!pip install twitter tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = '0vqmq8vkBGwFaOOQJPkk75wj9'\n",
    "CONSUMER_SECRET = 'F6FLN4514JXyq8IPmtIFQA9TI5TqJ3XFcxATrRhZ2GVQNDNhHf'\n",
    "ACCESS_TOKEN = '862710988822372352-dC0d1LzeLd5wodTA3BqjRtT9U2f7TQR'\n",
    "ACCESS_SECRET = 'J71AYBbH69nJCkqwPKV0YrqTDiUqjz0yOhNDJ9BGZ02kz'\n",
    "keys = {\n",
    "'CONSUMER_KEY': '0vqmq8vkBGwFaOOQJPkk75wj9',\n",
    "'CONSUMER_SECRET': 'F6FLN4514JXyq8IPmtIFQA9TI5TqJ3XFcxATrRhZ2GVQNDNhHf',\n",
    "'ACCESS_TOKEN': '862710988822372352-dC0d1LzeLd5wodTA3BqjRtT9U2f7TQR',\n",
    "'ACCESS_SECRET': 'J71AYBbH69nJCkqwPKV0YrqTDiUqjz0yOhNDJ9BGZ02kz'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299999 IamMannyyy:  i''m looking for someone to call, baby\n",
      "299998 REVSoccerClub:  two teams making each other better on the field. #development https://t.co/1ddktcjljx\n",
      "299997 taaaylorquinn:  how do you feel that you just cut me off and almost hit me whilst doing so, and now we are at the same red light\n",
      "299996 IamKacio:  work bound....  just trying to make it through\n",
      "299995 m1m_Z:  „Åà„ÄÅ„ÇÅ„Å£„Å°„ÇÉÈù¢ÁôΩ„ÅÑ\n",
      "299994 StuLovett:  @speakerryan you must be an idiot expecting people to believe inexperience is the reason trump has foot cemented in his mouth #shitforbrains\n",
      "299993 erinlaine:  honestly it''s so offensive when friends only watch your first insta story. https://t.co/1nun8oetpc\n",
      "299992 jhamby:  sorry, the title is \"throwing stones\". i should''ve double checked that.\n",
      "299991 PresidentialKel:  and i think that''s why it''s so funny üòÇüòÇüòÇ i read it in your voice üò≠ https://t.co/en9soonksa\n",
      "299990 funkvantan:  @macysorrelle thank you :))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2c663b6e81a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mtweet_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/twitter/stream.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# Decode all the things:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mdechunked_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_of_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0municode_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutf8_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdechunked_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/twitter/stream.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mready_to_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mready_to_read\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os,sys,inspect\n",
    "from time import sleep\n",
    "#currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "#parentdir = os.path.dirname(currentdir)\n",
    "#sys.path.insert(0,parentdir)\n",
    "\n",
    "from lib.twitter_keys import keys\n",
    "import json\n",
    "from twitter import Twitter, OAuth, TwitterHTTPError, TwitterStream\n",
    "\n",
    "\n",
    "#CONSUMER_KEY = keys['CONSUMER_KEY']\n",
    "#CONSUMER_SECRET = keys['CONSUMER_SECRET']\n",
    "\n",
    "#ACCESS_TOKEN = keys['ACCESS_TOKEN']\n",
    "#ACCESS_SECRET = keys['ACCESS_SECRET']\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### geo bounding for tweet location----------------------------------------------------####\n",
    "\n",
    "los_angeles = \"-118.670883,33.733477,-117.695847,34.290126\"\n",
    "Santa_Monica = \"-118.514757,33.980857,-118.417253,34.065264\"\n",
    "Dallas = \"-96.904907,32.761906,-96.684917,33.080035\"\n",
    "Midland_Odessa = \"-103.1575,31.4849,-101.5178,32.3591\"\n",
    "Sacramento_east = \"-121.8658,38.445,-120.2618,39.3598\"\n",
    "SFO = \"-122.5319,37.5751,-122.3438,37.824\"\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### connect to postgres----------------------------------------------------------------####\n",
    "\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "\n",
    "\n",
    "### ------------------------------------------------------------------------------------####\n",
    "### cleaning text ----------------------------------------------------------------------####\n",
    "\n",
    "def cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"'\",\"''\", text)\n",
    "    text = re.sub(\"{\",\"\\{\",text)\n",
    "    text = re.sub(\"}\",\"\\}\",text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "\n",
    "    #text = re.sub(\":\",\"\\:\",text)\n",
    "    return text\n",
    "\n",
    "### -------------------------------------------------------------------------------------####\n",
    "### cleaning tweet ----------------------------------------------------------------------####\n",
    "\n",
    "#from spacy.en import STOP_WORDS\n",
    "#from spacy.en import English\n",
    "#import nltk\n",
    "#nlp = English()\n",
    "def tweet_cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"'\",\"''\", text)\n",
    "    text = re.sub(\"{\",\"\\{\",text)\n",
    "    text = re.sub(\"}\",\"\\}\",text)\n",
    "    text = re.sub(r'http\\S+', '',text)\n",
    "    text = re.sub(r'@\\S+', '',text)\n",
    "    \n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    text = re.sub('\\n',' ',text) \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = re.sub(emoji_pattern, '', text)    \n",
    "#    text = ' '.join([i.lemma_ for i in nlp(text) \n",
    "#                   if i.orth_ not in STOP_WORDS])\n",
    "    \n",
    "    return text\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### Collecting tweets------------------------------------------------------------------####\n",
    "\n",
    "\n",
    "\n",
    "oauth = OAuth(ACCESS_TOKEN, ACCESS_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_stream = TwitterStream(auth=oauth)\n",
    "#iterator = twitter_stream.statuses.filter(locations=Santa_Monica+','+\\\n",
    "#                                          Midland_Odessa+','+Dallas+','+\\\n",
    "#                                          Sacramento_east+','+SFO)\n",
    "iterator = twitter_stream.statuses.filter(locations=los_angeles)\n",
    "tweet_count = 300000\n",
    "\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "for tweet in iterator:\n",
    "    tweet_count -= 1  \n",
    "   \n",
    "    try:\n",
    "        id_str = str(tweet['id_str'])\n",
    "    except:    \n",
    "        id_str = None\n",
    "    try:\n",
    "        screen_name = tweet['user']['screen_name']\n",
    "    except:\n",
    "        screen_name = None\n",
    "\n",
    "    tweet_content = cleaner(tweet['text'])\n",
    "    cleaned_tweet = tweet_cleaner(tweet['text'])\n",
    "    screen_name = tweet['user']['screen_name']\n",
    "    retweeted = tweet['retweeted']\n",
    "    retweet_count = tweet['retweet_count']\n",
    "    created_at = tweet['created_at']\n",
    "    date = tweet['created_at'][26:30]+'-'+tweet['created_at'][4:7]+'-'+tweet['created_at'][8:10]\n",
    "    time = tweet['created_at'][11:19]\n",
    "    get_hashtags = lambda tweet: \" \".join([i for i in tweet.split() if ('#' in i)])\n",
    "    hashtags1 = get_hashtags(tweet_content)\n",
    "    hashtags1 = re.sub('\\W',' ',hashtags1)\n",
    "    hashtags1 = re.sub('\\s+',' ',hashtags1)\n",
    "    try: \n",
    "        if len(hashtags1) > 1:\n",
    "            hashtags = hashtags1\n",
    "        else:\n",
    "            hashtags = None\n",
    "    except:\n",
    "        hashtags = None\n",
    "    try:\n",
    "        location =  cleaner(tweet['place']['full_name'])\n",
    "    except:\n",
    "        location = None\n",
    "    try:\n",
    "        country = tweet['place']['country']\n",
    "    except:\n",
    "        country = None\n",
    "    try:\n",
    "        place_type = tweet['place']['place_type']\n",
    "    except:\n",
    "        place_type = None\n",
    "    try:\n",
    "        latitude = tweet[\"geo\"][\"coordinates\"][0]\n",
    "        longitude = tweet[\"geo\"][\"coordinates\"][1]\n",
    "    except:\n",
    "        latitude = 0.0 \n",
    "        longitude = 0.0  \n",
    "    usr= tweet['user']\n",
    "    lang = tweet['lang']\n",
    "    try:\n",
    "        time_zone = cleaner(tweet['user']['time_zone'])\n",
    "    except:\n",
    "        time_zone = None    \n",
    "    sql_insert = '''insert into tweets_bkup_0607\n",
    "                        (\n",
    "                            id,\n",
    "                            screen_name,\n",
    "                            tweet_content,\n",
    "                            cleaned_tweet,\n",
    "                            hashtags,\n",
    "                            created_at,\n",
    "                            date,\n",
    "                            time,\n",
    "                            retweeted,\n",
    "                            retweet_count,\n",
    "                            location,\n",
    "                            country,\n",
    "                            place_type,\n",
    "                            latitude,\n",
    "                            longitude, \n",
    "                            time_zone,\n",
    "                            lang\n",
    "                        )\n",
    "                    values\n",
    "                        ('{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}');\n",
    "                 '''.format(id_str,\n",
    "                            screen_name,\n",
    "                            tweet_content,\n",
    "                            cleaned_tweet,\n",
    "                            hashtags,\n",
    "                            created_at,\n",
    "                            date,\n",
    "                            time,\n",
    "                            retweeted,\n",
    "                            retweet_count,\n",
    "                            location,\n",
    "                            country,\n",
    "                            place_type,\n",
    "                            latitude,\n",
    "                            longitude,\n",
    "                            time_zone,\n",
    "                            lang\n",
    "                           )\n",
    "    print(str(tweet_count)+' '+ screen_name+ ':  '+ tweet_content)\n",
    "    #print(latitude,longitude)\n",
    "    cur.execute(sql_insert)\n",
    "    \n",
    "    conn.commit()    \n",
    "    if tweet_count <= 0:\n",
    "        break\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-Jun-09'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet['created_at'][26:30]+'-'+tweet['created_at'][4:7]+'-'+tweet['created_at'][8:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02:06:00'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet['created_at'][11:19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "select count(*) from tweets;\n",
    "\n",
    "##### create able\n",
    "select * into tweets_bkup_0607 from tweets;\n",
    "\n",
    "CREATE TABLE tweets (\n",
    "    id TEXT, \n",
    "    tweet_content TEXT, \n",
    "    entities TEXT,\n",
    "    retweeted TEXT,\n",
    "    created_at TEXT,\n",
    "    regin TEXT,\n",
    "    country TEXT,\n",
    "    place_type TEXT,\n",
    "    geo_enabled boolean,\n",
    "    geo text,\n",
    "    time_zone TEXT,\n",
    "    lang TEXT,\n",
    "    usr text\n",
    "    );\n",
    "    \n",
    "##### drop table\n",
    "drop table tweets_bkup_0606;\n",
    "\n",
    "##### set ID/ Index\n",
    "alter table tweets alter column id set not null;\n",
    "alter table tweets add unique (id);\n",
    "\n",
    "create index on tweets (id);\n",
    "create index on tweets (tweet_content);\n",
    "\n",
    "##### clean table\n",
    "select count (*) from tweets where hashtags = 'None';\n",
    "select count (*) from tweets where hashtags is null;\n",
    "update tweets set hashtags = NULL where hashtags = 'None';\n",
    "\n",
    "select count(*) from tweets where lang != 'en';\n",
    "delete from tweets where lang != 'en';\n",
    "\n",
    "##### Docker - psql\n",
    "docker exec -it mypostgres psql postgres postgres\n",
    "\n",
    "##### In psql\n",
    "\\d tweets\n",
    "\\dt\n",
    "\\q\n",
    "\n",
    "##### get cloumns\n",
    "SELECT * FROM Northwind.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'tweets';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='54.191.217.176'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "cur = conn.cursor(cursor_factory=pgex.RealDictCursor)\n",
    "#cur.execute(sql_create)\n",
    "#cur.execute(sql_drop)\n",
    "#cur.execute(sql_insert)\n",
    "#conn.commit()\n",
    "cur.execute(sql_select)\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import psycopg2\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "oauth = OAuth(ACCESS_TOKEN, ACCESS_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_stream = TwitterStream(auth=oauth)\n",
    "iterator = twitter_stream.statuses.filter(locations=los_angeles_bb)\n",
    "tweet_count = 30\n",
    "\n",
    "\n",
    "\n",
    "# Twitter initialization\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "l = StreamListener()\n",
    "# Postgresql initialization\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# The table schema: CREATE TABLE tweets (id SERIAL PRIMARY KEY, tweet_id BIGINT NOT NULL, text VARCHAR NOT NULL, screen_name VARCHAR NOT NULL, author_id INTEGER, created_at VARCHAR NOT NULL, inserted_at TIMESTAMP NOT NULL)\n",
    "\n",
    "try:\n",
    "     \n",
    "    stream = Stream(auth, l)\n",
    "    count = tweet_count\n",
    "    iterator = stream.filter(locations=[-118.512139,34.003151,-118.433948,34.048961])\n",
    "    print(iterator)\n",
    "    for s in iterator:\n",
    "        # To remove duplicate entries\n",
    "        # See http://initd.org/psycopg/docs/faq.html for \"not all arguments converted during string formatting\"\n",
    "        cursor.execute(\"SELECT id FROM tweets WHERE text = %s;\", [s.text])\n",
    "        if cursor.rowcount == 0:\n",
    "            cursor.execute(\"INSERT INTO tweets (id, tweet_content, created_at) \\\n",
    "                           VALUES (%s, %s, %s, %s, %s, current_timestamp);\"\\\n",
    "                           , (s.id, s.text, s.created_at))\n",
    "            conn.commit()\n",
    "except tweepy.error.TweepError:\n",
    "    print (\"Whoops, could not fetch news!\")\n",
    "except UnicodeEncodeError:\n",
    "    pass\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
