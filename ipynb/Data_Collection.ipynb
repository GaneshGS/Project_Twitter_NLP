{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "#from lib.twitter_keys import keys\n",
    "!pip install twitter tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = '0vqmq8vkBGwFaOOQJPkk75wj9'\n",
    "CONSUMER_SECRET = 'F6FLN4514JXyq8IPmtIFQA9TI5TqJ3XFcxATrRhZ2GVQNDNhHf'\n",
    "ACCESS_TOKEN = '862710988822372352-dC0d1LzeLd5wodTA3BqjRtT9U2f7TQR'\n",
    "ACCESS_SECRET = 'J71AYBbH69nJCkqwPKV0YrqTDiUqjz0yOhNDJ9BGZ02kz'\n",
    "keys = {\n",
    "'CONSUMER_KEY': '0vqmq8vkBGwFaOOQJPkk75wj9',\n",
    "'CONSUMER_SECRET': 'F6FLN4514JXyq8IPmtIFQA9TI5TqJ3XFcxATrRhZ2GVQNDNhHf',\n",
    "'ACCESS_TOKEN': '862710988822372352-dC0d1LzeLd5wodTA3BqjRtT9U2f7TQR',\n",
    "'ACCESS_SECRET': 'J71AYBbH69nJCkqwPKV0YrqTDiUqjz0yOhNDJ9BGZ02kz'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os,sys,inspect\n",
    "from time import sleep\n",
    "#currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "#parentdir = os.path.dirname(currentdir)\n",
    "#sys.path.insert(0,parentdir)\n",
    "\n",
    "\n",
    "import json\n",
    "from twitter import Twitter, OAuth, TwitterHTTPError, TwitterStream\n",
    "CONSUMER_KEY = '0vqmq8vkBGwFaOOQJPkk75wj9'\n",
    "CONSUMER_SECRET = 'F6FLN4514JXyq8IPmtIFQA9TI5TqJ3XFcxATrRhZ2GVQNDNhHf'\n",
    "ACCESS_TOKEN = '862710988822372352-dC0d1LzeLd5wodTA3BqjRtT9U2f7TQR'\n",
    "ACCESS_SECRET = 'J71AYBbH69nJCkqwPKV0YrqTDiUqjz0yOhNDJ9BGZ02kz'\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### geo bounding for tweet location----------------------------------------------------####\n",
    "\n",
    "los_angeles = \"-118.670883,33.733477,-117.695847,34.290126\"\n",
    "Santa_Monica = \"-118.514757,33.980857,-118.417253,34.065264\"\n",
    "Dallas = \"-96.904907,32.761906,-96.684917,33.080035\"\n",
    "Midland_Odessa = \"-103.1575,31.4849,-101.5178,32.3591\"\n",
    "Sacramento_east = \"-121.8658,38.445,-120.2618,39.3598\"\n",
    "SFO = \"-122.5319,37.5751,-122.3438,37.824\"\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### connect to postgres----------------------------------------------------------------####\n",
    "\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "\n",
    "\n",
    "### ------------------------------------------------------------------------------------####\n",
    "### cleaning text ----------------------------------------------------------------------####\n",
    "\n",
    "def cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"'\",\"''\", text)\n",
    "    text = re.sub(\"{\",\"\\{\",text)\n",
    "    text = re.sub(\"}\",\"\\}\",text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "\n",
    "    #text = re.sub(\":\",\"\\:\",text)\n",
    "    return text\n",
    "\n",
    "### -------------------------------------------------------------------------------------####\n",
    "### cleaning tweet ----------------------------------------------------------------------####\n",
    "\n",
    "#from spacy.en import STOP_WORDS\n",
    "#from spacy.en import English\n",
    "#import nltk\n",
    "#nlp = English()\n",
    "def tweet_cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"'\",\"''\", text)\n",
    "    text = re.sub(\"{\",\"\\{\",text)\n",
    "    text = re.sub(\"}\",\"\\}\",text)\n",
    "    text = re.sub(r'http\\S+', '',text)\n",
    "    text = re.sub(r'@\\S+', '',text)\n",
    "    \n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    text = re.sub('\\n',' ',text) \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = re.sub(emoji_pattern, '', text)    \n",
    "#    text = ' '.join([i.lemma_ for i in nlp(text) \n",
    "#                   if i.orth_ not in STOP_WORDS])\n",
    "    \n",
    "    return text\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### Collecting tweets------------------------------------------------------------------####\n",
    "\n",
    "\n",
    "\n",
    "oauth = OAuth(ACCESS_TOKEN, ACCESS_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_stream = TwitterStream(auth=oauth)\n",
    "#iterator = twitter_stream.statuses.filter(locations=Santa_Monica+','+\\\n",
    "#                                          Midland_Odessa+','+Dallas+','+\\\n",
    "#                                          Sacramento_east+','+SFO)\n",
    "iterator = twitter_stream.statuses.filter(locations=los_angeles)\n",
    "tweet_count = 300000\n",
    "\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "for tweet in iterator:\n",
    "    if tweet['lang'] == 'en':   \n",
    "        tweet_count -= 1  \n",
    "\n",
    "        try:\n",
    "            id_str = str(tweet['id_str'])\n",
    "        except:    \n",
    "            pass\n",
    "        try:\n",
    "            screen_name = tweet['user']['screen_name']\n",
    "        except:\n",
    "            screen_name = None\n",
    "\n",
    "        tweet_content = cleaner(tweet['text'])\n",
    "        cleaned_tweet = tweet_cleaner(tweet['text'])\n",
    "        date = tweet['created_at'][26:30]+'-'+tweet['created_at'][4:7]+'-'+tweet['created_at'][8:10]\n",
    "        time = tweet['created_at'][11:19]\n",
    "        \n",
    "        screen_name = tweet['user']['screen_name']\n",
    "        retweeted = tweet['retweeted']\n",
    "        retweet_count = tweet['retweet_count']\n",
    "        created_at = tweet['created_at']\n",
    "        #date_time = \"to_timestamp(concat(substring('{}',27,4),'-',substring('{}',5,3),'-',\\\n",
    "        #        substring'({}',9,2),' ',substring('{}',11,9)),\\'YYYY-Mon-DD HH24:MI:SS') at time zone \\'UTC'\"\\\n",
    "        #        .format(created_at,created_at,created_at,created_at)\n",
    "        date_time = tweet['created_at'][26:30]+'-'+\\\n",
    "                    tweet['created_at'][4:7]+'-'+tweet['created_at'][8:10]+' '+tweet['created_at'][11:19]\n",
    "        get_hashtags = lambda tweet: \" \".join([i for i in tweet.split() if ('#' in i)])\n",
    "        hashtags1 = get_hashtags(tweet_content)\n",
    "        hashtags1 = re.sub('\\W',' ',hashtags1)\n",
    "        hashtags1 = re.sub('\\s+',' ',hashtags1)\n",
    "        try: \n",
    "            if len(hashtags1) > 1:\n",
    "                hashtags = hashtags1\n",
    "            else:\n",
    "                hashtags = None\n",
    "        except:\n",
    "            hashtags = None\n",
    "        try:\n",
    "            location =  cleaner(tweet['place']['full_name'])\n",
    "        except:\n",
    "            location = None\n",
    "        try:\n",
    "            country = tweet['place']['country']\n",
    "        except:\n",
    "            country = None\n",
    "        try:\n",
    "            place_type = tweet['place']['place_type']\n",
    "        except:\n",
    "            place_type = None\n",
    "        try:\n",
    "            latitude = tweet[\"geo\"][\"coordinates\"][0]\n",
    "            longitude = tweet[\"geo\"][\"coordinates\"][1]\n",
    "        except:\n",
    "            latitude = 0.0 \n",
    "            longitude = 0.0  \n",
    "        usr = tweet['user']\n",
    "        lang = tweet['lang']\n",
    "        try:\n",
    "            time_zone = cleaner(tweet['user']['time_zone'])\n",
    "        except:\n",
    "            time_zone = None    \n",
    "        sql_insert = '''insert into tweets \n",
    "                            (\n",
    "                                id,\n",
    "                                screen_name,\n",
    "                                tweet_content,\n",
    "                                cleaned_tweet,\n",
    "                                hashtags,\n",
    "                                created_at,\n",
    "                                date,\n",
    "                                time,\n",
    "                                date_time,\n",
    "                                retweeted,\n",
    "                                retweet_count,\n",
    "                                location,\n",
    "                                country,\n",
    "                                place_type,\n",
    "                                latitude,\n",
    "                                longitude, \n",
    "                                time_zone,\n",
    "                                lang\n",
    "                            )\n",
    "                        values\n",
    "                            ('{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}','{}');\n",
    "                     '''.format(id_str,\n",
    "                                screen_name,\n",
    "                                tweet_content,\n",
    "                                cleaned_tweet,\n",
    "                                hashtags,\n",
    "                                created_at,\n",
    "                                date,\n",
    "                                time,\n",
    "                                date_time,\n",
    "                                retweeted,\n",
    "                                retweet_count,\n",
    "                                location,\n",
    "                                country,\n",
    "                                place_type,\n",
    "                                latitude,\n",
    "                                longitude,\n",
    "                                time_zone,\n",
    "                                lang\n",
    "                               )\n",
    "        print(str(tweet_count)+' '+ screen_name+ ':  '+ tweet_content)\n",
    "        #print(latitude,longitude)\n",
    "        cur.execute(sql_insert)\n",
    "            \n",
    "\n",
    "        conn.commit()\n",
    "        if tweet_count <= 0:\n",
    "            break\n",
    "    else:\n",
    "        pass\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "update tweets set time = TO_TIMESTAMP(substring(created_at,11,9), 'HH24:MI:SS') where time is null;\n",
    "\n",
    "select created_at, concat(substring(created_at,27,4),'-',substring(created_at,5,3),'-',substring(created_at,9,2)) from tweets limit 1;\n",
    "\n",
    "update tweets set date = TO_date(concat(substring(created_at,27,4),'-',substring(created_at,5,3),'-',substring(created_at,9,2)), 'YYYY-Mon-DD') where date is null;\n",
    "\n",
    "update tweets set date_time = to_timestamp(concat(substring(created_at,27,4),'-',substring(created_at,5,3),'-',\n",
    "substring(created_at,9,2),' ',substring(created_at,11,9)),'YYYY-Mon-DD HH24:MI:SS') at time zone 'UTC';\n",
    "\n",
    "'''update tweets set date_time = to_timestamp(concat(substring(created_at,27,4),'-',substring(created_at,5,3),'-',\n",
    "substring(created_at,9,2),' ',substring(created_at,11,9)),'YYYY-Mon-DD HH24:MI:SS') at time zone 'UTC' where date_time is null;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet['created_at'][26:30]+'-'+tweet['created_at'][4:7]+'-'+tweet['created_at'][8:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet['created_at'][11:19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "select count(*) from tweets;\n",
    "\n",
    "##### create able\n",
    "select * into tweets_bkup_0607 from tweets;\n",
    "\n",
    "CREATE TABLE tweets (\n",
    "    id TEXT, \n",
    "    tweet_content TEXT, \n",
    "    entities TEXT,\n",
    "    retweeted TEXT,\n",
    "    created_at TEXT,\n",
    "    regin TEXT,\n",
    "    country TEXT,\n",
    "    place_type TEXT,\n",
    "    geo_enabled boolean,\n",
    "    geo text,\n",
    "    time_zone TEXT,\n",
    "    lang TEXT,\n",
    "    usr text\n",
    "    );\n",
    "    \n",
    "##### drop table\n",
    "drop table tweets_bkup_0606;\n",
    "\n",
    "##### set ID/ Index\n",
    "alter table tweets alter column id set not null;\n",
    "alter table tweets add unique (id);\n",
    "\n",
    "create index on tweets (id);\n",
    "create index on tweets (tweet_content);\n",
    "\n",
    "##### clean table\n",
    "select count (*) from tweets where hashtags = 'None';\n",
    "select count (*) from tweets where hashtags is null;\n",
    "update tweets set hashtags = NULL where hashtags = 'None';\n",
    "\n",
    "select count(*) from tweets where lang != 'en';\n",
    "delete from tweets where lang != 'en';\n",
    "\n",
    "##### Docker - psql\n",
    "docker exec -it mypostgres psql postgres postgres\n",
    "\n",
    "##### In psql\n",
    "\\d tweets\n",
    "\\dt\n",
    "\\q\n",
    "\n",
    "##### get cloumns\n",
    "SELECT * FROM Northwind.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'tweets';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='54.191.217.176'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "cur = conn.cursor(cursor_factory=pgex.RealDictCursor)\n",
    "#cur.execute(sql_create)\n",
    "#cur.execute(sql_drop)\n",
    "#cur.execute(sql_insert)\n",
    "#conn.commit()\n",
    "cur.execute(sql_select)\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os,sys,inspect\n",
    "from time import sleep\n",
    "#currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "#parentdir = os.path.dirname(currentdir)\n",
    "#sys.path.insert(0,parentdir)\n",
    "\n",
    "\n",
    "import json\n",
    "from twitter import Twitter, OAuth, TwitterHTTPError, TwitterStream\n",
    "CONSUMER_KEY = '0vqmq8vkBGwFaOOQJPkk75wj9'\n",
    "CONSUMER_SECRET = 'F6FLN4514JXyq8IPmtIFQA9TI5TqJ3XFcxATrRhZ2GVQNDNhHf'\n",
    "ACCESS_TOKEN = '862710988822372352-dC0d1LzeLd5wodTA3BqjRtT9U2f7TQR'\n",
    "ACCESS_SECRET = 'J71AYBbH69nJCkqwPKV0YrqTDiUqjz0yOhNDJ9BGZ02kz'\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### geo bounding for tweet location----------------------------------------------------####\n",
    "\n",
    "los_angeles = \"-118.670883,33.733477,-117.695847,34.290126\"\n",
    "Santa_Monica = \"-118.514757,33.980857,-118.417253,34.065264\"\n",
    "Dallas = \"-96.904907,32.761906,-96.684917,33.080035\"\n",
    "Midland_Odessa = \"-103.1575,31.4849,-101.5178,32.3591\"\n",
    "Sacramento_east = \"-121.8658,38.445,-120.2618,39.3598\"\n",
    "SFO = \"-122.5319,37.5751,-122.3438,37.824\"\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### connect to postgres----------------------------------------------------------------####\n",
    "\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "\n",
    "\n",
    "### ------------------------------------------------------------------------------------####\n",
    "### cleaning text ----------------------------------------------------------------------####\n",
    "\n",
    "def cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"'\",\"''\", text)\n",
    "    text = re.sub(\"{\",\"\\{\",text)\n",
    "    text = re.sub(\"}\",\"\\}\",text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "\n",
    "    #text = re.sub(\":\",\"\\:\",text)\n",
    "    return text\n",
    "\n",
    "### -------------------------------------------------------------------------------------####\n",
    "### cleaning tweet ----------------------------------------------------------------------####\n",
    "\n",
    "#from spacy.en import STOP_WORDS\n",
    "#from spacy.en import English\n",
    "#import nltk\n",
    "#nlp = English()\n",
    "def tweet_cleaner(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"'\",\"''\", text)\n",
    "    text = re.sub(\"{\",\"\\{\",text)\n",
    "    text = re.sub(\"}\",\"\\}\",text)\n",
    "    text = re.sub(r'http\\S+', '',text)\n",
    "    text = re.sub(r'@\\S+', '',text)\n",
    "    \n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    text = re.sub('\\n',' ',text) \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = re.sub(emoji_pattern, '', text)    \n",
    "#    text = ' '.join([i.lemma_ for i in nlp(text) \n",
    "#                   if i.orth_ not in STOP_WORDS])\n",
    "    \n",
    "    return text\n",
    "\n",
    "### -----------------------------------------------------------------------------------####\n",
    "### Collecting tweets------------------------------------------------------------------####\n",
    "\n",
    "\n",
    "\n",
    "oauth = OAuth(ACCESS_TOKEN, ACCESS_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_stream = TwitterStream(auth=oauth)\n",
    "#iterator = twitter_stream.statuses.filter(locations=Santa_Monica+','+\\\n",
    "#                                          Midland_Odessa+','+Dallas+','+\\\n",
    "#                                          Sacramento_east+','+SFO)\n",
    "iterator = twitter_stream.statuses.filter(locations=los_angeles)\n",
    "tweet_count =2\n",
    "\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "for tweet in iterator:\n",
    "    tweet_count -= 1  \n",
    "    print(tweet)\n",
    "    if tweet['coordinates'] !='None':\n",
    "    if tweet_count <= 0:\n",
    "        break   \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
