{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "import pickle\n",
    "import redis\n",
    "\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "\n",
    "\n",
    "sql_select = '''select cleaned_tweet \n",
    "                from tweets where (date_time >= NOW() - '7 day'::INTERVAL) ;'''\n",
    "cur = conn.cursor(cursor_factory=pgex.RealDictCursor)\n",
    "cur.execute(sql_select)\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "df = pd.DataFrame(rows)\n",
    "df.reset_index(inplace = True)\n",
    "\n",
    "redis_ip = '34.211.59.66'\n",
    "r = redis.StrictRedis(redis_ip)\n",
    "\n",
    "tfd_svd_pipe = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('svd',TruncatedSVD(n_components=50))\n",
    "])\n",
    "\n",
    "tfd_svd_pipe.fit(df['cleaned_tweet'])\n",
    "\n",
    "tfd_svd_pipe = pickle.dumps(tfd_svd_pipe)\n",
    "r.set('tweets_tfd_svd_pipe', tfd_svd_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "this_host='34.211.59.66'\n",
    "this_user='postgres'\n",
    "this_password='postgres'\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "\n",
    "#sql_select = '''select created_at, location, tweet_content, cleaned_tweet, vector from tweets ORDER BY RANDOM() LIMIT 300000;'''\n",
    "sql_select = '''select cleaned_tweet \n",
    "                from tweets where (date_time >= NOW() - '7 day'::INTERVAL);'''\n",
    "cur = conn.cursor(cursor_factory=pgex.RealDictCursor)\n",
    "cur.execute(sql_select)\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "df = pd.DataFrame(rows)\n",
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "r.flushall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "!pip install redis\n",
    "import redis\n",
    "redis_ip = '34.211.59.66'\n",
    "r = redis.StrictRedis(redis_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfd_svd_pipe = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('svd',TruncatedSVD(n_components=25))\n",
    "])\n",
    "tfd = tfd_pipe.steps[0][1]\n",
    "svd = tfd_pipe.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_tfidf_fit = tfidf_vectorizer.fit(df['cleaned_tweet'].values.astype('U'))\n",
    "tweet_tfidf_transform = tfidf_vectorizer.fit_transform(df['cleaned_tweet'].values.astype('U'))\n",
    "#tweet_tfidf_fit = tfidf_vectorizer.fit(df['hashtags'].values.astype('U'))\n",
    "#tweet_tfidf_transform = tfidf_vectorizer.fit_transform(df['hashtags'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_tfidf_fit = pickle.dumps(tweet_tfidf_fit)\n",
    "r.set('tweet_tfidf_fit', tweet_tfidf_fit)\n",
    "tweet_tfidf_transform = pickle.dumps(tweet_tfidf_transform)\n",
    "r.set('tweet_tfidf_fit_transform', tweet_tfidf_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import redis\n",
    "redis_ip = '34.211.59.66'\n",
    "r = redis.StrictRedis(redis_ip)\n",
    "tweet_tfidf = pickle.loads(r.get('tweet_tfidf_fit_transform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_tfidf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVD = TruncatedSVD(n_components = 300)\n",
    "SVD_model_fit = SVD.fit(tweet_tfidf)\n",
    "r = redis.StrictRedis(redis_ip)\n",
    "LSA = pickle.dumps(SVD_model_fit)\n",
    "r.set('tweet_SVD_fit', LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
